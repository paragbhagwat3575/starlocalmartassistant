<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Star LocalMart Shopping Assistant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
  <style>
    :root{
      --bg1:#0b1020; --bg2:#1b2a55; --glass:rgba(255,255,255,.08); --stroke:rgba(255,255,255,.14);
      --txt:#f3f6ff; --sub:#c6d2ff; --pill:#eef2ff; --accent:#7aa2ff;
    }
    html,body{height:100%}
    body{
      margin:0; font-family: ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, Arial;
      color:var(--txt);
      background: radial-gradient(1200px 800px at 10% 10%, #18214d 0%, transparent 60%),
                  radial-gradient(1200px 900px at 90% 90%, #0e1639 0%, transparent 60%),
                  linear-gradient(160deg, var(--bg1), var(--bg2));
      padding: max(16px, env(safe-area-inset-top)) max(16px, env(safe-area-inset-right)) max(16px, env(safe-area-inset-bottom)) max(16px, env(safe-area-inset-left));
      overflow:hidden;
    }

    .wrap{height:100%; display:grid; place-items:center}
    .card{
      width:min(1100px, 96vw);
      height: calc(100vh - 32px);             /* full-height so buttons stay visible */
      display:grid; grid-template-columns: 420px 1fr; gap: clamp(14px, 3vw, 28px);
      background:var(--glass); border:1px solid var(--stroke); border-radius:24px;
      backdrop-filter: blur(12px);
      box-shadow: 0 20px 60px rgba(0,0,0,.35), inset 0 1px 0 rgba(255,255,255,.06);
      padding: clamp(16px, 3vw, 28px);
      min-height: 560px;
    }
    @media (max-width: 820px){ .card{ grid-template-columns: 1fr; } }

    /* Left column */
    .hero{
      display:grid; grid-template-rows:auto auto 1fr auto auto; gap:14px;
      min-height:0;
    }
    .brand{ font-weight:800; letter-spacing:.4px; color:var(--sub); font-size:clamp(14px,1.8vw,18px) }
    .title{ font-weight:900; line-height:1.05; font-size: clamp(26px, 4.5vw, 38px) }
    .gifWrap img {
  width: 80%;
  height: 100%;
  object-fit: contain;   /* ✅ keeps full logo visible */
  display: block;
  padding: 10px;         /* optional: some breathing space */
  background: #fff;      /* optional: neutral background behind SVG */
  border-radius: 16px;   /* matches container roundness */
}


    @media (max-height: 820px){
      .gifWrap{ aspect-ratio: 16 / 10; max-height: 42vh; }
      .title{ font-size: clamp(22px, 3.6vw, 34px) }
    }

    .controls{ display:grid; gap:10px; align-content:start }
    .pill{
      display:inline-flex; align-items:center; gap:8px;
      border:1px solid var(--stroke); background:rgba(255,255,255,.06);
      border-radius:999px; padding:6px 10px; color:#dbe3ff; font-size:12px;
      width:fit-content;
    }
    .dot{ width:8px; height:8px; border-radius:50%; background:#94a3b8 }
    .dot.speaking{ background:#a78bfa; box-shadow:0 0 16px 4px #a78bfa55 }
    .dot.listening{ background:#6ee7a8; box-shadow:0 0 16px 4px #6ee7a855 }

    .cta{ display:flex; gap:10px; align-items:center; flex-wrap:wrap }
    button.primary{
      appearance:none; border:none; cursor:pointer; user-select:none; touch-action:manipulation;
      font-weight:800; letter-spacing:.3px; font-size:16px;
      background: radial-gradient(200% 200% at 0% 0%, #ffffff 0%, #d7e5ff 40%, #b7cdfb 100%);
      color:#0b1b3a; padding:14px 22px; border-radius:14px; min-width:180px;
      box-shadow: 0 12px 30px rgba(90,120,255,.35), inset 0 1px 0 #fff8;
      transition: transform .1s ease, box-shadow .2s ease, opacity .2s ease, background .2s ease, color .2s ease;
    }
    button.primary:hover{ transform: translateY(-1px); box-shadow: 0 16px 38px rgba(90,120,255,.4) }
    button.primary:active{ transform: translateY(1px) }
    .hint{ color:#d1dbff; opacity:.85; font-size:13px }

    /* Right column – chat */
    .chatWrap{ display:grid; grid-template-rows:auto 1fr; gap:12px; min-height:0 }
    .stateRow{ display:flex; align-items:center; gap:10px; justify-content:flex-start; }
    .stateLabel{ color:#dbe3ff; font-size:14px }

    .chat{
      background:rgba(255,255,255,.04); border:1px solid var(--stroke);
      border-radius:16px; padding:14px; overflow:auto; min-height:160px; max-height:100%;
      scroll-behavior:smooth;
    }
    .bubble{
      max-width: 85%; padding:12px 14px; border-radius:14px; line-height:1.35; margin:6px 0;
      background: rgba(255,255,255,.06); border:1px solid var(--stroke);
    }
    .bubble.me{ margin-left:auto; background:rgba(122,162,255,.14); border-color:#88a6ff55 }
    .bubble small{ display:block; opacity:.7; margin-top:4px }

    .eq { display:inline-grid; grid-auto-flow:column; gap:2px; margin-left:6px }
    .bar{ width:3px; height:10px; background:#a78bfa; border-radius:2px; animation: up 900ms ease-in-out infinite }
    .bar:nth-child(2){ animation-delay:.1s } .bar:nth-child(3){ animation-delay:.2s } .bar:nth-child(4){ animation-delay:.3s }
    @keyframes up { 0%,100{ transform: scaleY(.5) } 50%{ transform: scaleY(1.4) } }

    /* PTT visual states */
    button.primary#pttBtn[data-state="listening"]{
      background: radial-gradient(200% 200% at 0% 0%, #d4ffe6 0%, #b2f5d6 40%, #7be2b4 100%) !important;
      color:#063a22 !important;
      box-shadow: 0 12px 30px rgba(64,202,134,.45), 0 0 0 3px rgba(64,202,134,.15) inset !important;
    }
    button.primary#pttBtn[data-state="speaking"]{
      background: radial-gradient(200% 200% at 0% 0%, #efe3ff 0%, #d7c6ff 40%, #bda4ff 100%) !important;
      color:#2f1159 !important;
    }
    button.primary#pttBtn:disabled{ opacity:.6; filter:saturate(.7); cursor:not-allowed }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <!-- LEFT -->
      <section class="hero">
        <div class="brand">Star LocalMart</div>
        <div class="title">Shopping Assistant</div>

        <div class="gifWrap">
<img src="logo-grl.svg" alt="GRL Logo">
        </div>

        <div class="controls">
          <div class="cta">
            <button id="startBtn" class="primary">Start</button>
            <button id="pttBtn" class="primary" style="min-width:200px">Hold to Talk</button>
            <span id="statePill" class="pill"><span id="dot" class="dot"></span><span id="pillLabel">Ready</span></span>
          </div>
          <div class="hint">Press & Hold to Talk (or hold <b>Spacebar</b>). The mic is closed when you’re not holding.</div>
        </div>
      </section>

      <!-- RIGHT -->
      <section class="chatWrap" aria-live="polite">
        <div class="stateRow">
          <span id="stateLabel" class="stateLabel">Idle</span>
          <span id="eq" class="eq" style="display:none"><span class="bar"></span><span class="bar"></span><span class="bar"></span><span class="bar"></span></span>
        </div>
        <div id="chat" class="chat"></div>
      </section>
    </div>
  </div>

  <audio id="remoteAudio" autoplay></audio>
  <script>
    // === CONFIG ===
    const TOKEN_ENDPOINT = "https://getstarlocalmartrealtimeassitant1-319132888215.asia-south1.run.app/";
    const MODEL = "gpt-realtime";
    const VOICE = "marin";

    // UI
    const btn = document.getElementById("startBtn");
    const pttBtn = document.getElementById("pttBtn");
    const chatEl = document.getElementById("chat");
    const stateLabel = document.getElementById("stateLabel");
    const pillLabel = document.getElementById("pillLabel");
    const dot = document.getElementById("dot");
    const eq = document.getElementById("eq");
    const remoteAudio = document.getElementById("remoteAudio");

    // WebRTC state
    let pc=null, dc=null, micStream=null, ephemeralKey=null;
    let isActive = false, isStartingOrEnding = false, pttActive = false;

    // Buffers for appending to chat
    let aiTextBuffer = "";
    let userTextBuffer = "";

    function say(text, who="ai"){
      if(!text) return;
      const div = document.createElement("div");
      div.className = "bubble" + (who==="me" ? " me" : "");
      div.textContent = text;
      chatEl.appendChild(div);
      chatEl.scrollTop = chatEl.scrollHeight;
    }

    function setState(label, mode){
      stateLabel.textContent = label; pillLabel.textContent = label;
      dot.classList.remove("speaking","listening"); eq.style.display = "none";
      if(mode==="speaking"){ dot.classList.add("speaking"); eq.style.display = "inline-grid"; }
      if(mode==="listening"){ dot.classList.add("listening"); }
      updatePTTEnabled();
    }

    function setMicEnabled(enabled){
      try { micStream?.getTracks().forEach(t => t.enabled = enabled); } catch {}
    }
    function isAssistantSpeaking(){ return dot.classList.contains("speaking"); }

    function setTurnDetection(enabled){
      if (!dc || dc.readyState !== "open") return;
      const td = enabled ? { type: "server_vad" } : null;
      dc.send(JSON.stringify({ type:"session.update", session:{ audio:{ input:{ turn_detection: td }}}}));
    }

    function canTalkNow(){
      return isActive && !isAssistantSpeaking() && dc?.readyState === "open";
    }

    function setPTTVisual(listening=false, speaking=false){
      const state = speaking ? 'speaking' : (listening ? 'listening' : '');
      pttBtn.dataset.state = state;
      if (speaking){
        pttBtn.textContent = "Speaking…"; pttBtn.setAttribute('aria-pressed','false');
      } else if (listening){
        pttBtn.textContent = "Release to Send"; pttBtn.setAttribute('aria-pressed','true');
      } else {
        pttBtn.textContent = "Hold to Talk"; pttBtn.setAttribute('aria-pressed','false');
      }
      void pttBtn.offsetHeight;
    }

    function pttDown(){
      if (!canTalkNow()) return;
      pttActive = true;
      setTurnDetection(true);
      setMicEnabled(true);
      requestAnimationFrame(() => setPTTVisual(true, false));
      setState("Listening…","listening");
    }
    function pttUp(){
      if (!pttActive) return;
      pttActive = false;
      setMicEnabled(false);
      requestAnimationFrame(() => setPTTVisual(false, false));
      // server VAD will commit; response.create sent on commit
    }

    function extractEphemeralKey(json){
      if (!json) return null;
      if (typeof json.value === "string") return json.value;
      if (json.client_secret?.value) return json.client_secret.value;
      if (json.clientSecret?.value)  return json.clientSecret.value;
      if (json.secret?.value)        return json.secret.value;
      return null;
    }

    async function getClientSecret(){
      const r = await fetch(TOKEN_ENDPOINT, {
        method:"POST", headers:{ "Content-Type":"application/json" },
        body: JSON.stringify({ model: MODEL, voice: VOICE, session_type: "realtime" })
      });
      const j = await r.json();
      const ek = extractEphemeralKey(j);
      if(!ek) throw new Error("Ephemeral key not found");
      return ek;
    }

    function setupPeer(){
      pc = new RTCPeerConnection();
      pc.ontrack = (e)=>{ remoteAudio.srcObject = e.streams[0]; };

      dc = pc.createDataChannel("oai-events");
      dc.onopen = ()=>{
        if (!isActive) return;

        // Enable audio + text outputs
        dc.send(JSON.stringify({ type:"session.update", session:{ output_modalities:["audio","text"] }}));

        // Enable automatic VAD
        dc.send(JSON.stringify({ type:"session.update", session:{ audio:{ input:{ turn_detection:{ type:"server_vad" }}}}}));

        // Enable input audio transcription so we get user transcripts
        dc.send(JSON.stringify({ type:"session.update", session:{
          input_audio_transcription: { model: "whisper-1" }
        }}));

        // Optional: set initial system behavior to "Sales Coach"
        dc.send(JSON.stringify({ type:"session.update", session:{
          instructions: "You are Sarvada AI Sales Coach. Be concise, practical, and strictly sales-focused (prospecting, discovery, qualification, objections, proposals, negotiation, closing, renewals, account growth). Avoid topics outside sales."
        }}));

        // initial greeting
        dc.send(JSON.stringify({ type:"response.create" }));

        setState("Connected","listening");
        updatePTTEnabled();
      };

      dc.onmessage = (evt)=>{
        if (!isActive) return;
        let m;
        try { m = JSON.parse(evt.data); } catch { return; }
        handleServerEvent(m);
      };

      pc.addTransceiver("audio", { direction:"sendrecv" });
    }

    function handleServerEvent(m){
      if (!isActive) return;

      // ---- USER transcript (speech -> text) ----
      if (m.type === "input_audio_transcript.delta" && typeof m.delta === "string") {
        userTextBuffer += m.delta;
        return;
      }
      if (m.type === "input_audio_transcript.done") {
        const finalUser = (userTextBuffer || "").trim();
        if (finalUser) say(finalUser, "me");
        userTextBuffer = "";
        return;
      }

      // ---- AI output (audio transcript or plain text) ----
      if (m.type === "response.output_audio_transcript.delta" && typeof m.delta === "string") {
        aiTextBuffer += m.delta; return;
      }
      if (m.type === "response.output_audio_transcript.done") {
        const finalAi = (aiTextBuffer || "").trim();
        if (finalAi) say(finalAi, "ai");
        aiTextBuffer = ""; return;
      }
      if (m.type === "response.output_text.delta" && typeof m.delta === "string") {
        aiTextBuffer += m.delta; return;
      }
      if (m.type === "response.output_text.done") {
        const finalAi = (aiTextBuffer || "").trim();
        if (finalAi) say(finalAi, "ai");
        aiTextBuffer = ""; return;
      }

      // ---- Playback + mic state ----
      if (m.type === "output_audio_buffer.started"){
        setTurnDetection(false); setMicEnabled(false);
        setPTTVisual(false, true); setState("Speaking…","speaking"); return;
      }
      if (m.type === "output_audio_buffer.stopped"){
        setState("Listening…","listening"); setTurnDetection(true); setMicEnabled(false);
        setPTTVisual(false, false); return;
      }

      // ---- Commit: when server decides user's turn ended, ask for response ----
      if (m.type === "input_audio_buffer.committed"){
        if (dc?.readyState === "open") dc.send(JSON.stringify({ type:"response.create" }));
        return;
      }
    }

    async function startSession(){
      if (isActive || isStartingOrEnding) return;
      isStartingOrEnding = true; btn.disabled = true; pttBtn.disabled = true;

      try{
        setState("Requesting mic…");
        micStream = await navigator.mediaDevices.getUserMedia({ audio:true });
        micStream.getTracks().forEach(t => t.enabled = false); // start muted

        setState("Fetching token…"); setPTTVisual(false, false);
        ephemeralKey = await getClientSecret();

        setState("Connecting…");
        setupPeer();
        micStream.getTracks().forEach(t => pc.addTrack(t, micStream));

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);

        const url = `https://api.openai.com/v1/realtime/calls?model=${encodeURIComponent(MODEL)}`;
        const sdpRes = await fetch(url, {
          method:"POST", body: offer.sdp,
          headers:{ Authorization:`Bearer ${ephemeralKey}`, "Content-Type":"application/sdp" }
        });
        const answer = await sdpRes.text();
        if(!sdpRes.ok || !answer.startsWith("v=")) throw new Error("Realtime failed");
        await pc.setRemoteDescription({ type:"answer", sdp: answer });

        isActive = true;
        btn.textContent = "End";
        setState("Listening…","listening");
      }catch(e){
        alert(e?.message || e);
        await endSession(true);
      }finally{
        isStartingOrEnding = false; btn.disabled = false; updatePTTEnabled(); setPTTVisual(false, false);
      }
    }

    async function endSession(silent=false){
      if (!isActive && !isStartingOrEnding && !pc) return;
      isStartingOrEnding = true; btn.disabled = true; pttBtn.disabled = true;

      try {
        try { dc?.send(JSON.stringify({ type:"response.cancel" })); } catch {}
        try { micStream?.getTracks().forEach(t => t.stop()); } catch {}
        try { pc?.close(); } catch {}
      } finally {
        pc=null; dc=null; micStream=null; ephemeralKey=null;
        isActive = false; pttActive = false;
        btn.textContent = "Start";
        if (!silent) setState("Ended");
        isStartingOrEnding = false; btn.disabled = false; updatePTTEnabled(); setPTTVisual(false, false);
      }
    }

    function updatePTTEnabled(){
      const canUse = isActive && !isAssistantSpeaking();
      pttBtn.disabled = !canUse && !pttActive;     // keep enabled while holding
      if (pttBtn.disabled) setPTTVisual(false, false);
    }

    // Start/End toggle
    btn.addEventListener("click", async () => {
      if (isStartingOrEnding) return;
      if (isActive) { await endSession(); } else { await startSession(); }
    });

    // PTT events (mouse/touch)
    pttBtn.addEventListener("mousedown", pttDown);
    pttBtn.addEventListener("touchstart", (e)=>{ e.preventDefault(); pttDown(); }, { passive:false });
    ["mouseup","mouseleave","touchend","touchcancel"].forEach(evt => pttBtn.addEventListener(evt, pttUp));

    // PTT via Spacebar
    window.addEventListener("keydown", (e)=>{ if (e.code === "Space" && !e.repeat){ e.preventDefault(); pttDown(); }});
    window.addEventListener("keyup", (e)=>{ if (e.code === "Space"){ e.preventDefault(); pttUp(); }});

    // Clean up on unload
    window.addEventListener("beforeunload", () => { try { dc?.send(JSON.stringify({ type:"response.cancel" })); } catch {} });
  </script>
</body>
</html>